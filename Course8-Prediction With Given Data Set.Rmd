---
title: "Course 8:Prediction with given dataset in R"
author: "Sudipto Mitra"
date: "May, 2018"
output:
    html_document:
    highlight: haddock
    theme: united
keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary

Six participants activities are tracked ny data collection from devices like Jawbone Up, Nike FuelBand, and Fitbit. Predictable variable is created by asking the performers to perform some activities. 
The participants are performing both corrent and incorrect activities both,the goal of this project is to predict the manner in which they did the exercise.

## Preprocesing 

###Data
Training and test datasets are downloaded for analysis. The data is not complete i.e. there are empty values. The empty values along with metadata columns in the first columns are not considered. Since there are huge number of columns (100), PCA is used to reduce the number of principal components 


https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv


https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

### Reproducibility
Reproduceability
An overall pseudo-random number generator seed was set at 1234 for all code. In order to reproduce the results below, the same seed should be used.
```{r seed}
set.seed(1234)
library(caret)
library(randomForest)
library(ggplot2)
library(e1071)
```

## Model Building Approach
Our outcome variable is classe, a factor variable with 5 levels. For this data set, "participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in 5 different fashions:


## Loading & Cleaning Data 
```{r Analysis}
# Place data files in working directory
#Load Training data
training<-read.csv("pml-training.csv",na.strings = c("NA"," ","#DIV/0!"))
#Load Test Data
 test<-read.csv("pml-testing.csv",na.strings = c("NA"," ","#DIV/0!"))

#get training set rows
trrows=dim(training)[1]
#get empty value measures
NA_pct_cols<-sapply(1:ncol(training),function (i) {sum(is.na(training[,i]))/trrows})
NA_pct_cols<-data.frame(NA_percent=NA_pct_cols,colpos=1:160)

#get 95 pct+ columns and removing them...
NA_pct_cols<-subset(NA_pct_cols,NA_percent>0.95)
training<-training[,-NA_pct_cols$colpos]
training<-training[complete.cases(training),]
test<-test[,-NA_pct_cols$colpos]

#Removing 1st 5 metadata columns
training<-training[,-(1:5)]
test<-test[,-(1:5)]

#seperating 'the target'classe' variable
train_target<-training$classe
training<-training[,-55]

training$new_window<-as.numeric(factor(training$new_window))
test$new_window<-as.numeric(factor(test$new_window))

```

##Applying PCA On the Cleaned Data
PCA applied to reduce the no of variables of the cleaned data

```{r PCA}
c1<-prcomp(training,scale = T)
c2<-(c1$sdev)^2
c3<-cumsum(c2/sum(c2))

plot(c3,xlab="Principal Components",ylab="Cum. Proportion of Variance Explained",
              type="b",main="Cum Var. explained Vs Principal Component")

#38 principal components are selected as predictor in the training and test data
training<-data.frame(c1$x[,1:38],classe=train_target)

test<-predict(c1,newdata=test)
#selecting 38 components
test<-test[,1:38]
```
##Cross Validation
Cross validation with 80/20 division of training dataset into training and test dataset
```{r Crossvalidation}
training_sub_ind<-createDataPartition(training$classe, p=0.80, list=FALSE)
training_sub<-training[training_sub_ind,]
test_sub<-training[-training_sub_ind,]
```
##Model training
```{r modeltrain,echo=T, results='hide'}
#generating machine model
model1<-svm(classe~.,data=training_sub,scale=T)
#Details of machine model:
model1

# generating random forest model
model2<-randomForest(classe ~ ., data=training_sub)
#Details of random forest model
model2

#Predict classes in test subset using svm
predict_classe1<-predict(model1,test_sub[,-39])

#Predict classes in test subset using Random forest model
predict_classe2<-predict(model2,test_sub[,-39])


# Generating confusion matrix...
confusionMatrix(predict_classe1, test_sub$classe) #Check accuracy
confusionMatrix(predict_classe2, test_sub$classe) #Check accuracy
```

Accuracy of random forest is better (~98%). So "model2" is chosen t for prediction with the test set

##Conclusion
```{r prediction}
#Predicting classes and output to csv file...
final<-predict(model2,test)
final
write.csv(final,"final.csv")
```